{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este é o notebook que foi utilizado no colab (para processamento e memória) para treinar os modelos de fato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlLzBpcOZGzn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy the file from your Google Drive's main folder\n",
        "!cp /content/drive/MyDrive/data2.zip .\n",
        "\n",
        "# Unzip the file\n",
        "!unzip data2.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXieHzUgV-mZ"
      },
      "source": [
        "#### Data formatting for training and eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNae3ptzV-mZ",
        "outputId": "4d8ff2b7-89c9-434f-f2f8-cc6be0de3b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 251471 files belonging to 35 classes.\n",
            "Found 10650 files belonging to 35 classes.\n",
            "✅ Found 35 classes: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
            "✅ Data preparation complete and optimized.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# --- Configuration ---\n",
        "BATCH_SIZE = 32\n",
        "IMG_HEIGHT = 30\n",
        "IMG_WIDTH = 40\n",
        "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH)\n",
        "\n",
        "# --- Define paths ---\n",
        "caminho_train = 'data/augmented_data'\n",
        "caminho_eval = 'data/processed_eval'\n",
        "\n",
        "# --- Load Training and Validation Data ---\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    caminho_train,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    color_mode='grayscale',\n",
        "    image_size=IMG_SHAPE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    caminho_eval,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    color_mode='grayscale',\n",
        "    image_size=IMG_SHAPE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# --- THE FIX: Get class_names BEFORE you modify the dataset ---\n",
        "class_names = train_ds.class_names\n",
        "print(f\"✅ Found {len(class_names)} classes: {class_names}\")\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# --- Normalize and Optimize ---\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print(\"✅ Data preparation complete and optimized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPPjOe7AV-ma"
      },
      "source": [
        "### Model construction, training and eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7cMW6FyV-ma"
      },
      "source": [
        "#### modular CNN function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I72w6YnovPpJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "\n",
        "def create_model(input_shape, num_classes, filters_per_layer=[32, 64], dense_units=128):\n",
        "    \"\"\"Creates a flexible CNN model.\"\"\"\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(tf.keras.Input(shape=input_shape))\n",
        "\n",
        "    # Convolutional blocks\n",
        "    for filters in filters_per_layer:\n",
        "        model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Classifier head\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_units, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5)) # Dropout is a key regularizer\n",
        "    model.add(Dense(num_classes, activation='softmax', dtype='float32')) # Output layer\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKgWkul9V-mb"
      },
      "source": [
        "#### Find best learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8qJQ0Et1vXwk",
        "outputId": "18d0a325-0fca-4c1f-d337-297b1fb112b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Running Experiment: lr_1e-3 ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4480</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">573,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,515</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4480\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m573,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │         \u001b[38;5;34m4,515\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,795</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m597,795\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,347</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m597,347\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7ms/step - accuracy: 0.9280 - loss: 0.2808 - val_accuracy: 0.9952 - val_loss: 0.0192\n",
            "Epoch 2/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9929 - loss: 0.0237 - val_accuracy: 0.9941 - val_loss: 0.0204\n",
            "Epoch 3/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0134 - val_accuracy: 0.9945 - val_loss: 0.0227\n",
            "Epoch 4/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0102 - val_accuracy: 0.9962 - val_loss: 0.0156\n",
            "Epoch 5/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0074 - val_accuracy: 0.9960 - val_loss: 0.0240\n",
            "Epoch 6/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0072 - val_accuracy: 0.9959 - val_loss: 0.0243\n",
            "Epoch 7/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0053 - val_accuracy: 0.9954 - val_loss: 0.0252\n",
            "Epoch 8/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9967 - val_loss: 0.0210\n",
            "Epoch 9/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.9964 - val_loss: 0.0246\n",
            "Epoch 10/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9960 - val_loss: 0.0278\n",
            "Epoch 11/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0043 - val_accuracy: 0.9952 - val_loss: 0.0320\n",
            "Epoch 12/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9968 - val_loss: 0.0240\n",
            "Epoch 13/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9968 - val_loss: 0.0222\n",
            "Epoch 14/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9962 - val_loss: 0.0235\n",
            "Epoch 15/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9962 - val_loss: 0.0286\n",
            "Epoch 16/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9962 - val_loss: 0.0319\n",
            "Epoch 17/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9964 - val_loss: 0.0264\n",
            "\n",
            "--- Running Experiment: lr_5e-4 ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4480</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">573,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,515</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4480\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m573,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │         \u001b[38;5;34m4,515\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,795</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m597,795\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,347</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m597,347\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.3489 - val_accuracy: 0.9957 - val_loss: 0.0163\n",
            "Epoch 2/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9938 - loss: 0.0218 - val_accuracy: 0.9954 - val_loss: 0.0177\n",
            "Epoch 3/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0120 - val_accuracy: 0.9938 - val_loss: 0.0228\n",
            "Epoch 4/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0079 - val_accuracy: 0.9950 - val_loss: 0.0209\n",
            "Epoch 5/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0063 - val_accuracy: 0.9963 - val_loss: 0.0155\n",
            "Epoch 6/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 0.9952 - val_loss: 0.0208\n",
            "Epoch 7/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9973 - val_loss: 0.0148\n",
            "Epoch 8/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9962 - val_loss: 0.0181\n",
            "Epoch 9/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9965 - val_loss: 0.0186\n",
            "Epoch 10/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9957 - val_loss: 0.0263\n",
            "Epoch 11/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9952 - val_loss: 0.0308\n",
            "Epoch 12/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9965 - val_loss: 0.0208\n",
            "\n",
            "--- Running Experiment: lr_1e-4 ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4480</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">573,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,515</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4480\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m573,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │         \u001b[38;5;34m4,515\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,795</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m597,795\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,347</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m597,347\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 0.6569 - val_accuracy: 0.9947 - val_loss: 0.0246\n",
            "Epoch 2/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.9917 - loss: 0.0386 - val_accuracy: 0.9948 - val_loss: 0.0199\n",
            "Epoch 3/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0170 - val_accuracy: 0.9961 - val_loss: 0.0151\n",
            "Epoch 4/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0108 - val_accuracy: 0.9956 - val_loss: 0.0186\n",
            "Epoch 5/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0071 - val_accuracy: 0.9964 - val_loss: 0.0138\n",
            "Epoch 6/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0053 - val_accuracy: 0.9954 - val_loss: 0.0191\n",
            "Epoch 7/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 0.9964 - val_loss: 0.0178\n",
            "Epoch 8/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 0.9963 - val_loss: 0.0173\n",
            "Epoch 9/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.9967 - val_loss: 0.0156\n",
            "Epoch 10/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9962 - val_loss: 0.0165\n",
            "Epoch 11/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9954 - val_loss: 0.0190\n",
            "Epoch 12/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9959 - val_loss: 0.0212\n",
            "Epoch 13/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9967 - val_loss: 0.0188\n",
            "Epoch 14/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9962 - val_loss: 0.0181\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# --- Setup ---\n",
        "INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\n",
        "NUM_CLASSES = len(class_names) # Get number of classes from the loaded data\n",
        "\n",
        "# --- Define Your Experiments ---\n",
        "experiments = [\n",
        "    {'id': 'lr_1e-3', 'learning_rate': 1e-3},\n",
        "    {'id': 'lr_5e-4', 'learning_rate': 5e-4},\n",
        "    {'id': 'lr_1e-4', 'learning_rate': 1e-4},\n",
        "]\n",
        "\n",
        "for config in experiments:\n",
        "    print(f\"\\n--- Running Experiment: {config['id']} ---\")\n",
        "\n",
        "    model = create_model(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=config['learning_rate']),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    model.summary()\n",
        "\n",
        "    log_dir = os.path.join(\"logs\", config['id'])\n",
        "    model_path = os.path.join(\"models\", f\"{config['id']}_best_model.keras\")\n",
        "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "    callbacks = [\n",
        "        TensorBoard(log_dir=log_dir),\n",
        "        ModelCheckpoint(filepath=model_path, save_best_only=True, monitor='val_accuracy', mode='max'),\n",
        "        EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=100, # Set high, EarlyStopping will handle it\n",
        "        validation_data=val_ds,\n",
        "        callbacks=callbacks\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPbc0vkOilCh"
      },
      "source": [
        "#### Learning the best capacity and dropout rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "xCHiY21Aikdd",
        "outputId": "43664e8a-fbe1-4ad0-e244-f294fb3b4f03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m6060/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0049"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2467429897.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     ]\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Set high, EarlyStopping will handle it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# --- Updated create_model function to accept variable dropout rates ---\n",
        "def create_model(input_shape, num_classes, filters_per_layer=[32, 64], dense_units=128, dropout_rate=0.5):\n",
        "    \"\"\"Creates a flexible CNN model with adjustable dropout.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(tf.keras.Input(shape=input_shape))\n",
        "\n",
        "    for filters in filters_per_layer:\n",
        "        model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_units, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax', dtype='float32'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- Experiment Set A: Find Ideal Capacity ---\n",
        "BEST_LEARNING_RATE = 5e-4\n",
        "\n",
        "capacity_experiments = [\n",
        "    {'id': 'capacity_small', 'filters': [16, 32], 'dense': 64},\n",
        "    {'id': 'capacity_medium', 'filters': [32, 64], 'dense': 128}, # Baseline\n",
        "    {'id': 'capacity_large2', 'filters': [64, 128], 'dense': 256},\n",
        "]\n",
        "\n",
        "for config in capacity_experiments:\n",
        "    print(f\"\\n--- Running Capacity Experiment: {config['id']} ---\")\n",
        "    model = create_model(\n",
        "        input_shape=INPUT_SHAPE,\n",
        "        num_classes=NUM_CLASSES,\n",
        "        filters_per_layer=config['filters'],\n",
        "        dense_units=config['dense']\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=BEST_LEARNING_RATE),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    model.summary()\n",
        "\n",
        "    log_dir = os.path.join(\"logs\", config['id'])\n",
        "    model_path = os.path.join(\"models\", f\"{config['id']}_best_model.keras\")\n",
        "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "    callbacks = [\n",
        "        TensorBoard(log_dir=log_dir),\n",
        "        ModelCheckpoint(filepath=model_path, save_best_only=True, monitor='val_accuracy', mode='max'),\n",
        "        EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=100, # Set high, EarlyStopping will handle it\n",
        "        validation_data=val_ds,\n",
        "        callbacks=callbacks\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FZMt6HKi7Iq"
      },
      "source": [
        "#### Find best dropout rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lVP4vnwai99P",
        "outputId": "345c7d1d-3503-4b07-9f77-99947d2a93ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Running Dropout Experiment: dropout_0.3 ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_24          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_25          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4480</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">573,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_26          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,515</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_24          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_16 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_25          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_17 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4480\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m573,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_26          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │         \u001b[38;5;34m4,515\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,795</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m597,795\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,347</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m597,347\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 5ms/step - accuracy: 0.9408 - loss: 0.2471 - val_accuracy: 0.9892 - val_loss: 0.0364\n",
            "Epoch 2/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0136 - val_accuracy: 0.9948 - val_loss: 0.0189\n",
            "Epoch 3/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9965 - val_loss: 0.0165\n",
            "Epoch 4/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0049 - val_accuracy: 0.9962 - val_loss: 0.0199\n",
            "Epoch 5/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9955 - val_loss: 0.0254\n",
            "Epoch 6/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9961 - val_loss: 0.0240\n",
            "Epoch 7/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9961 - val_loss: 0.0206\n",
            "Epoch 8/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9949 - val_loss: 0.0272\n",
            "\n",
            "--- Running Dropout Experiment: dropout_0.4 ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_27          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_28          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4480</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">573,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_29          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,515</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_27          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_18 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_28          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_19 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4480\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m573,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_29          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │         \u001b[38;5;34m4,515\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,795</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m597,795\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,347</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m597,347\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 0.9307 - loss: 0.2794 - val_accuracy: 0.9918 - val_loss: 0.0269\n",
            "Epoch 2/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0154 - val_accuracy: 0.9940 - val_loss: 0.0236\n",
            "Epoch 3/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0096 - val_accuracy: 0.9951 - val_loss: 0.0202\n",
            "Epoch 4/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 0.9968 - val_loss: 0.0131\n",
            "Epoch 5/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9964 - val_loss: 0.0163\n",
            "Epoch 6/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 0.9969 - val_loss: 0.0183\n",
            "Epoch 7/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9968 - val_loss: 0.0175\n",
            "Epoch 8/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9952 - val_loss: 0.0244\n",
            "Epoch 9/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 0.9969 - val_loss: 0.0227\n",
            "Epoch 10/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.9963 - val_loss: 0.0234\n",
            "Epoch 11/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9970 - val_loss: 0.0173\n",
            "Epoch 12/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9972 - val_loss: 0.0148\n",
            "Epoch 13/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9967 - val_loss: 0.0220\n",
            "Epoch 14/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9977 - val_loss: 0.0185\n",
            "Epoch 15/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9969 - val_loss: 0.0208\n",
            "Epoch 16/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9973 - val_loss: 0.0203\n",
            "Epoch 17/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9975 - val_loss: 0.0214\n",
            "Epoch 18/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.9969 - val_loss: 0.0221\n",
            "Epoch 19/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9968 - val_loss: 0.0195\n",
            "\n",
            "--- Running Dropout Experiment: dropout_0.5 ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_30          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4480</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">573,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,515</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_30          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_21 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4480\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m573,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │         \u001b[38;5;34m4,515\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,795</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m597,795\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,347</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m597,347\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.3383 - val_accuracy: 0.9907 - val_loss: 0.0316\n",
            "Epoch 2/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0211 - val_accuracy: 0.9949 - val_loss: 0.0162\n",
            "Epoch 3/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0124 - val_accuracy: 0.9964 - val_loss: 0.0149\n",
            "Epoch 4/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 0.9971 - val_loss: 0.0137\n",
            "Epoch 5/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.9979 - loss: 0.0071 - val_accuracy: 0.9962 - val_loss: 0.0155\n",
            "Epoch 6/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9961 - val_loss: 0.0178\n",
            "Epoch 7/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0045 - val_accuracy: 0.9950 - val_loss: 0.0228\n",
            "Epoch 8/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9960 - val_loss: 0.0258\n",
            "Epoch 9/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.9951 - val_loss: 0.0233\n"
          ]
        }
      ],
      "source": [
        "# --- Experiment Set B: Find Ideal Dropout Rate ---\n",
        "BEST_LEARNING_RATE = 5e-4\n",
        "BEST_CAPACITY = {'filters': [32,64], 'dense': 128}\n",
        "\n",
        "dropout_experiments = [\n",
        "    {'id': 'dropout_0.3', 'rate': 0.3},\n",
        "    {'id': 'dropout_0.4', 'rate': 0.4},\n",
        "    {'id': 'dropout_0.5', 'rate': 0.5},\n",
        "]\n",
        "\n",
        "for config in dropout_experiments:\n",
        "    print(f\"\\n--- Running Dropout Experiment: {config['id']} ---\")\n",
        "    model = create_model(\n",
        "        input_shape=INPUT_SHAPE,\n",
        "        num_classes=NUM_CLASSES,\n",
        "        filters_per_layer=BEST_CAPACITY['filters'],\n",
        "        dense_units=BEST_CAPACITY['dense'],\n",
        "        dropout_rate=config['rate']\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(BEST_LEARNING_RATE),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    model.summary()\n",
        "\n",
        "    log_dir = os.path.join(\"logs\", config['id'])\n",
        "    model_path = os.path.join(\"models\", f\"{config['id']}_best_model.keras\")\n",
        "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "    callbacks = [\n",
        "        TensorBoard(log_dir=log_dir),\n",
        "        ModelCheckpoint(filepath=model_path, save_best_only=True, monitor='val_accuracy', mode='max'),\n",
        "        EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=100,\n",
        "        validation_data=val_ds,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luaj9_WOmVV1"
      },
      "source": [
        "#### Test adamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KoIwVSXGmiht",
        "outputId": "106ef4a0-b20f-41c7-b0e8-0210b0e821e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Running Experiment: AdamW Optimizer ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4480</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">573,568</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_35          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,515</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_22 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_23 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4480\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m573,568\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_35          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │         \u001b[38;5;34m4,515\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,795</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m597,795\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597,347</span> (2.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m597,347\u001b[0m (2.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.9318 - loss: 0.2777 - val_accuracy: 0.9929 - val_loss: 0.0219\n",
            "Epoch 2/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0150 - val_accuracy: 0.9955 - val_loss: 0.0175\n",
            "Epoch 3/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0084 - val_accuracy: 0.9937 - val_loss: 0.0263\n",
            "Epoch 4/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0063 - val_accuracy: 0.9959 - val_loss: 0.0189\n",
            "Epoch 5/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9954 - val_loss: 0.0164\n",
            "Epoch 6/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9946 - val_loss: 0.0285\n",
            "Epoch 7/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9949 - val_loss: 0.0235\n",
            "Epoch 8/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9960 - val_loss: 0.0235\n",
            "Epoch 9/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9969 - val_loss: 0.0208\n",
            "Epoch 10/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9962 - val_loss: 0.0188\n",
            "Epoch 11/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9954 - val_loss: 0.0234\n",
            "Epoch 12/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9959 - val_loss: 0.0231\n",
            "Epoch 13/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9969 - val_loss: 0.0195\n",
            "Epoch 14/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9945 - val_loss: 0.0327\n",
            "Epoch 15/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9962 - val_loss: 0.0207\n",
            "Epoch 16/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9963 - val_loss: 0.0205\n",
            "Epoch 17/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9962 - val_loss: 0.0221\n",
            "Epoch 18/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9962 - val_loss: 0.0258\n",
            "Epoch 19/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 8.6986e-04 - val_accuracy: 0.9958 - val_loss: 0.0285\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "BEST_LEARNING_RATE = 5e-4\n",
        "BEST_FILTERS = [32,64]\n",
        "BEST_DENSE_UNITS = 128\n",
        "BEST_DROPOUT_RATE = 0.4\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "print(\"--- Running Experiment: AdamW Optimizer ---\")\n",
        "\n",
        "# 2. Create your best model architecture\n",
        "model_adamw = create_model(\n",
        "    input_shape=INPUT_SHAPE,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    filters_per_layer=BEST_FILTERS,\n",
        "    dense_units=BEST_DENSE_UNITS,\n",
        "    dropout_rate=BEST_DROPOUT_RATE\n",
        ")\n",
        "\n",
        "# 3. Compile the model using the AdamW optimizer\n",
        "model_adamw.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(\n",
        "        learning_rate=BEST_LEARNING_RATE,\n",
        "        weight_decay=1e-4  # A common default for weight decay\n",
        "    ),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_adamw.summary()\n",
        "\n",
        "# 4. Set up callbacks to save the best version of this model\n",
        "model_path = 'models/adamw_best_model.keras'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "callbacks_adamw = [\n",
        "    ModelCheckpoint(filepath=model_path, save_best_only=True, monitor='val_accuracy', mode='max'),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# 5. Train the model\n",
        "history_adamw = model_adamw.fit(\n",
        "    train_ds,\n",
        "    epochs=100, # Set high, EarlyStopping will handle it\n",
        "    validation_data=val_ds,\n",
        "    callbacks=callbacks_adamw\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tqhl_9_lDVp"
      },
      "source": [
        "#### Final model training\n",
        "Given the best parameterst found, train the best model with increased patience and decreasing learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WprW79jhlLbk",
        "outputId": "73fe2406-945d-41d1-a612-269915ce0d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting final training with LR decay ---\n",
            "Epoch 1/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9293 - loss: 0.2889 - val_accuracy: 0.9936 - val_loss: 0.0207 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0170 - val_accuracy: 0.9952 - val_loss: 0.0174 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0093 - val_accuracy: 0.9940 - val_loss: 0.0249 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0056 - val_accuracy: 0.9961 - val_loss: 0.0157 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9961 - val_loss: 0.0164 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.9951 - val_loss: 0.0191 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.9962 - val_loss: 0.0202 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9968 - val_loss: 0.0177 - learning_rate: 2.5000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 9.5212e-04 - val_accuracy: 0.9968 - val_loss: 0.0181 - learning_rate: 2.5000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 6.1000e-04 - val_accuracy: 0.9976 - val_loss: 0.0142 - learning_rate: 2.5000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 6.3798e-04 - val_accuracy: 0.9970 - val_loss: 0.0169 - learning_rate: 2.5000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 4.6820e-04 - val_accuracy: 0.9965 - val_loss: 0.0168 - learning_rate: 2.5000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 3.4781e-04 - val_accuracy: 0.9983 - val_loss: 0.0137 - learning_rate: 2.5000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 5.7106e-04 - val_accuracy: 0.9977 - val_loss: 0.0154 - learning_rate: 2.5000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 4.6231e-04 - val_accuracy: 0.9964 - val_loss: 0.0190 - learning_rate: 2.5000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 5.8409e-04 - val_accuracy: 0.9972 - val_loss: 0.0180 - learning_rate: 2.5000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 2.8060e-04 - val_accuracy: 0.9973 - val_loss: 0.0176 - learning_rate: 1.2500e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 2.0253e-04 - val_accuracy: 0.9968 - val_loss: 0.0169 - learning_rate: 1.2500e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2547e-04 - val_accuracy: 0.9974 - val_loss: 0.0182 - learning_rate: 1.2500e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.6433e-05 - val_accuracy: 0.9971 - val_loss: 0.0183 - learning_rate: 6.2500e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.2261e-05 - val_accuracy: 0.9972 - val_loss: 0.0180 - learning_rate: 6.2500e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.8684e-05 - val_accuracy: 0.9974 - val_loss: 0.0181 - learning_rate: 6.2500e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.2444e-05 - val_accuracy: 0.9972 - val_loss: 0.0184 - learning_rate: 3.1250e-05\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7da24e2a0a50>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# --- Step 4a: Re-train with Learning Rate Decay & More Patience ---\n",
        "BEST_LR = 5e-4\n",
        "BEST_FILTERS = [32,64]\n",
        "BEST_DENSE = 128\n",
        "BEST_DROPOUT = 0.4\n",
        "\n",
        "print(\"--- Starting final training with LR decay ---\")\n",
        "\n",
        "final_model = create_model(\n",
        "    input_shape=INPUT_SHAPE,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    filters_per_layer=BEST_FILTERS,\n",
        "    dense_units=BEST_DENSE,\n",
        "    dropout_rate=BEST_DROPOUT\n",
        ")\n",
        "\n",
        "final_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=BEST_LR),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Set up callbacks with more patience and the LR scheduler\n",
        "final_callbacks = [\n",
        "    ModelCheckpoint(filepath='models/model_with_decay.keras', save_best_only=True, monitor='val_accuracy', mode='max'),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=10), # Increased patience\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3) # Add scheduler\n",
        "]\n",
        "final_model.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=final_callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcVuA2wmvSKM"
      },
      "source": [
        "#### If needed (based on training logs), implement a custom callback to stop training at peak performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qhESUgCvRdC",
        "outputId": "d2f8ee9d-a82b-41f2-f0fe-56e554f2cebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting final training with LR decay ---\n",
            "Epoch 1/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 0.9312 - loss: 0.2754 - val_accuracy: 0.9949 - val_loss: 0.0176 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0165 - val_accuracy: 0.9920 - val_loss: 0.0240 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0089 - val_accuracy: 0.9958 - val_loss: 0.0231 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0061 - val_accuracy: 0.9964 - val_loss: 0.0192 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.9954 - val_loss: 0.0190 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 0.9958 - val_loss: 0.0200 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9954 - val_loss: 0.0192 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9971 - val_loss: 0.0165 - learning_rate: 2.5000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 7.8585e-04 - val_accuracy: 0.9962 - val_loss: 0.0195 - learning_rate: 2.5000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 7.6828e-04 - val_accuracy: 0.9965 - val_loss: 0.0177 - learning_rate: 2.5000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 5.7195e-04 - val_accuracy: 0.9972 - val_loss: 0.0151 - learning_rate: 2.5000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5626e-04 - val_accuracy: 0.9970 - val_loss: 0.0156 - learning_rate: 1.2500e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 2.5173e-04 - val_accuracy: 0.9974 - val_loss: 0.0130 - learning_rate: 1.2500e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5893e-04 - val_accuracy: 0.9975 - val_loss: 0.0128 - learning_rate: 1.2500e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4180e-04 - val_accuracy: 0.9976 - val_loss: 0.0123 - learning_rate: 1.2500e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 2.8464e-04 - val_accuracy: 0.9970 - val_loss: 0.0153 - learning_rate: 1.2500e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4493e-04 - val_accuracy: 0.9971 - val_loss: 0.0165 - learning_rate: 1.2500e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5286e-04 - val_accuracy: 0.9974 - val_loss: 0.0134 - learning_rate: 1.2500e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 1.3677e-04 - val_accuracy: 0.9975 - val_loss: 0.0139 - learning_rate: 6.2500e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.2524e-05 - val_accuracy: 0.9976 - val_loss: 0.0131 - learning_rate: 6.2500e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.8676e-05 - val_accuracy: 0.9977 - val_loss: 0.0128 - learning_rate: 6.2500e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.0546e-05 - val_accuracy: 0.9977 - val_loss: 0.0142 - learning_rate: 6.2500e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8537e-05\\nReached 0.9978 validation accuracy. Halting training.\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8535e-05 - val_accuracy: 0.9979 - val_loss: 0.0135 - learning_rate: 6.2500e-05\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7da251034710>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "class HaltOnThreshold(tf.keras.callbacks.Callback):\n",
        "  \"\"\"Callback that halts training when validation accuracy reaches a threshold.\"\"\"\n",
        "  def __init__(self, threshold):\n",
        "    super(HaltOnThreshold, self).__init__()\n",
        "    self.threshold = threshold\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    val_accuracy = logs.get(\"val_accuracy\")\n",
        "    if val_accuracy is not None and val_accuracy >= self.threshold:\n",
        "      print(f\"\\\\nReached {self.threshold:.4f} validation accuracy. Halting training.\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# --- Step 4a: Re-train with Learning Rate Decay & More Patience ---\n",
        "BEST_LR = 5e-4\n",
        "BEST_FILTERS = [32, 64]\n",
        "BEST_DENSE = 128\n",
        "BEST_DROPOUT = 0.4\n",
        "\n",
        "print(\"--- Starting final training with LR decay ---\")\n",
        "\n",
        "final_model = create_model(\n",
        "    input_shape=INPUT_SHAPE,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    filters_per_layer=BEST_FILTERS,\n",
        "    dense_units=BEST_DENSE,\n",
        "    dropout_rate=BEST_DROPOUT\n",
        ")\n",
        "\n",
        "final_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=BEST_LR),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(filepath='models/model_with_decay3.keras', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "early_stopper = EarlyStopping(monitor='val_accuracy', patience=10)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3)\n",
        "halt_on_target = HaltOnThreshold(threshold=0.9978)\n",
        "\n",
        "final_callbacks = [\n",
        "    model_checkpoint,\n",
        "    early_stopper,\n",
        "    lr_scheduler,\n",
        "    halt_on_target\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "final_model.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=final_callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGvoB4wwovY4",
        "outputId": "7bcc8357-d1da-47bd-be70-daade2037b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Zipping 'models' and 'logs' directories...\n",
            "  adding: models/ (stored 0%)\n",
            "  adding: models/model_with_decay2.keras (deflated 7%)\n",
            "  adding: models/dropout_0.4_best_model.keras (deflated 7%)\n",
            "  adding: models/capacity_large2_best_model.keras (deflated 7%)\n",
            "  adding: models/final_model_quant.tflite (deflated 13%)\n",
            "  adding: models/capacity_large_best_model.keras (deflated 7%)\n",
            "  adding: models/model_with_decay3.keras (deflated 7%)\n",
            "  adding: models/final_model.keras (deflated 7%)\n",
            "  adding: models/lr_1e-4_best_model.keras (deflated 8%)\n",
            "  adding: models/adamw_best_model.keras (deflated 7%)\n",
            "  adding: models/model_with_decay.keras (deflated 7%)\n",
            "  adding: models/lr_1e-3_best_model.keras (deflated 7%)\n",
            "  adding: models/capacity_medium_best_model.keras (deflated 7%)\n",
            "  adding: models/capacity_small_best_model.keras (deflated 10%)\n",
            "  adding: models/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: models/lr_5e-4_best_model.keras (deflated 7%)\n",
            "  adding: models/dropout_0.3_best_model.keras (deflated 8%)\n",
            "  adding: models/dropout_0.5_best_model.keras (deflated 8%)\n",
            "  adding: logs/ (stored 0%)\n",
            "  adding: logs/dropout_0.3/ (stored 0%)\n",
            "  adding: logs/dropout_0.3/validation/ (stored 0%)\n",
            "  adding: logs/dropout_0.3/validation/events.out.tfevents.1753951747.c5a90d915fe0.1125.15.v2 (deflated 70%)\n",
            "  adding: logs/dropout_0.3/train/ (stored 0%)\n",
            "  adding: logs/dropout_0.3/train/events.out.tfevents.1753951702.c5a90d915fe0.1125.14.v2 (deflated 83%)\n",
            "  adding: logs/capacity_large/ (stored 0%)\n",
            "  adding: logs/capacity_large/validation/ (stored 0%)\n",
            "  adding: logs/capacity_large/validation/events.out.tfevents.1753950998.c5a90d915fe0.1125.11.v2 (deflated 71%)\n",
            "  adding: logs/capacity_large/train/ (stored 0%)\n",
            "  adding: logs/capacity_large/train/events.out.tfevents.1753950946.c5a90d915fe0.1125.10.v2 (deflated 83%)\n",
            "  adding: logs/capacity_small/ (stored 0%)\n",
            "  adding: logs/capacity_small/validation/ (stored 0%)\n",
            "  adding: logs/capacity_small/validation/events.out.tfevents.1753950068.c5a90d915fe0.1125.7.v2 (deflated 72%)\n",
            "  adding: logs/capacity_small/train/ (stored 0%)\n",
            "  adding: logs/capacity_small/train/events.out.tfevents.1753950030.c5a90d915fe0.1125.6.v2 (deflated 83%)\n",
            "  adding: logs/dropout_0.5/ (stored 0%)\n",
            "  adding: logs/dropout_0.5/validation/ (stored 0%)\n",
            "  adding: logs/dropout_0.5/validation/events.out.tfevents.1753952769.c5a90d915fe0.1125.19.v2 (deflated 71%)\n",
            "  adding: logs/dropout_0.5/train/ (stored 0%)\n",
            "  adding: logs/dropout_0.5/train/events.out.tfevents.1753952727.c5a90d915fe0.1125.18.v2 (deflated 83%)\n",
            "  adding: logs/dropout_0.4/ (stored 0%)\n",
            "  adding: logs/dropout_0.4/validation/ (stored 0%)\n",
            "  adding: logs/dropout_0.4/validation/events.out.tfevents.1753952045.c5a90d915fe0.1125.17.v2 (deflated 76%)\n",
            "  adding: logs/dropout_0.4/train/ (stored 0%)\n",
            "  adding: logs/dropout_0.4/train/events.out.tfevents.1753952002.c5a90d915fe0.1125.16.v2 (deflated 82%)\n",
            "  adding: logs/lr_1e-3/ (stored 0%)\n",
            "  adding: logs/lr_1e-3/validation/ (stored 0%)\n",
            "  adding: logs/lr_1e-3/validation/events.out.tfevents.1753948094.c5a90d915fe0.1125.1.v2 (deflated 75%)\n",
            "  adding: logs/lr_1e-3/train/ (stored 0%)\n",
            "  adding: logs/lr_1e-3/train/events.out.tfevents.1753948039.c5a90d915fe0.1125.0.v2 (deflated 82%)\n",
            "  adding: logs/lr_1e-4/ (stored 0%)\n",
            "  adding: logs/lr_1e-4/validation/ (stored 0%)\n",
            "  adding: logs/lr_1e-4/validation/events.out.tfevents.1753949169.c5a90d915fe0.1125.5.v2 (deflated 74%)\n",
            "  adding: logs/lr_1e-4/train/ (stored 0%)\n",
            "  adding: logs/lr_1e-4/train/events.out.tfevents.1753949128.c5a90d915fe0.1125.4.v2 (deflated 83%)\n",
            "  adding: logs/capacity_medium/ (stored 0%)\n",
            "  adding: logs/capacity_medium/validation/ (stored 0%)\n",
            "  adding: logs/capacity_medium/validation/events.out.tfevents.1753950396.c5a90d915fe0.1125.9.v2 (deflated 74%)\n",
            "  adding: logs/capacity_medium/train/ (stored 0%)\n",
            "  adding: logs/capacity_medium/train/events.out.tfevents.1753950354.c5a90d915fe0.1125.8.v2 (deflated 82%)\n",
            "  adding: logs/lr_5e-4/ (stored 0%)\n",
            "  adding: logs/lr_5e-4/validation/ (stored 0%)\n",
            "  adding: logs/lr_5e-4/validation/events.out.tfevents.1753948700.c5a90d915fe0.1125.3.v2 (deflated 73%)\n",
            "  adding: logs/lr_5e-4/train/ (stored 0%)\n",
            "  adding: logs/lr_5e-4/train/events.out.tfevents.1753948658.c5a90d915fe0.1125.2.v2 (deflated 83%)\n",
            "  adding: logs/capacity_large2/ (stored 0%)\n",
            "  adding: logs/capacity_large2/validation/ (stored 0%)\n",
            "  adding: logs/capacity_large2/validation/events.out.tfevents.1753951507.c5a90d915fe0.1125.13.v2 (deflated 63%)\n",
            "  adding: logs/capacity_large2/train/ (stored 0%)\n",
            "  adding: logs/capacity_large2/train/events.out.tfevents.1753951457.c5a90d915fe0.1125.12.v2 (deflated 84%)\n",
            "\n",
            "Copying ocr_project_backup_final.zip to Google Drive...\n",
            "\n",
            "✅ Backup complete! 'ocr_project_backup_final.zip' is now saved in your Google Drive.\n"
          ]
        }
      ],
      "source": [
        "# Backing up the data, just in case\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "backup_filename = \"ocr_project_backup_final.zip\"\n",
        "drive_path = f\"/content/drive/MyDrive/{backup_filename}\"\n",
        "\n",
        "print(\"\\nZipping 'models' and 'logs' directories...\")\n",
        "!zip -r {backup_filename} ./models ./logs\n",
        "\n",
        "print(f\"\\nCopying {backup_filename} to Google Drive...\")\n",
        "!cp {backup_filename} /content/drive/MyDrive/\n",
        "\n",
        "print(f\"\\n✅ Backup complete! '{backup_filename}' is now saved in your Google Drive.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHyUpMuvzSeU"
      },
      "source": [
        "After training it, set a very small learning rate to find the absolute minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fteGtLLMzR2J",
        "outputId": "7766040e-da83-4c9f-a968-b1a2d020c324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting final polish with tiny learning rate ---\n",
            "Epoch 1/5\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.7927e-05 - val_accuracy: 0.9978 - val_loss: 0.0133\n",
            "Epoch 2/5\n",
            "\u001b[1m7854/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8357e-05\\nReached 0.9980 validation accuracy. Halting training.\n",
            "\u001b[1m7859/7859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8354e-05 - val_accuracy: 0.9980 - val_loss: 0.0132\n",
            "✅ Final model saved as models/final_model.keras\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Step 4b: Final Polish with Tiny Learning Rate ---\n",
        "print(\"\\n--- Starting final polish with tiny learning rate ---\")\n",
        "\n",
        "# Load the best model from the previous step\n",
        "polished_model = tf.keras.models.load_model('models/model_with_decay3.keras')\n",
        "\n",
        "# Re-compile with a very small learning rate\n",
        "polished_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "halt_on_target = HaltOnThreshold(threshold=0.998)\n",
        "\n",
        "# Train for just a few more epochs\n",
        "polished_model.fit(train_ds, epochs=5, validation_data=val_ds, callbacks=[halt_on_target])\n",
        "\n",
        "# Save your final, fully-trained model\n",
        "polished_model.save('models/final_model.keras')\n",
        "print(\"✅ Final model saved as models/final_model.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5giLnTycV-mb"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkKCvqkz2_56",
        "outputId": "da3a4449-b6d1-467c-d650-82b62b088990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading best model from: models/final_model.keras\n",
            "\n",
            "Evaluating on the processed evaluation dataset:\n",
            "333/333 - 2s - 5ms/step - accuracy: 0.9980 - loss: 0.0132\n",
            "\n",
            "Evaluation Accuracy: 99.80282%\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# --- Evaluate the Best Model ---\n",
        "best_model_path = 'models/final_model.keras'\n",
        "\n",
        "print(f\"Loading best model from: {best_model_path}\")\n",
        "loaded_model = tf.keras.models.load_model(best_model_path)\n",
        "\n",
        "# Evaluate the loaded model on your actual evaluation data\n",
        "print(\"\\nEvaluating on the processed evaluation dataset:\")\n",
        "loss, accuracy = loaded_model.evaluate(val_ds, verbose=2)\n",
        "\n",
        "print(f\"\\nEvaluation Accuracy: {accuracy*100:.5f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF0uZQeeV-mc"
      },
      "source": [
        "### Post-training quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6srije0RsJoU"
      },
      "source": [
        "#### Benchmark final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLkD9RhQsCNv",
        "outputId": "ec5c6da1-da99-415e-dfd1-f07532775f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating FP32 model accuracy...\n",
            "FP32 Model Accuracy: 99.8028%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: input_layer_14\n",
            "Received: inputs=('Tensor(shape=(1, 30, 40, 1))', 'Tensor(shape=(1,))')\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Timing FP32 model inference...\n",
            "FP32 Model Inference Time: 70.4129 ms\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "fp32_model = tf.keras.models.load_model('models/final_model.keras')\n",
        "\n",
        "# --- 1. Measure Accuracy ---\n",
        "print(\"Evaluating FP32 model accuracy...\")\n",
        "loss, fp32_accuracy = fp32_model.evaluate(val_ds, verbose=0)\n",
        "print(f\"FP32 Model Accuracy: {fp32_accuracy * 100:.4f}%\")\n",
        "\n",
        "# --- 2. Measure Inference Speed ---\n",
        "inference_batch = next(iter(val_ds.unbatch().batch(1)))\n",
        "\n",
        "# warm up\n",
        "_ = fp32_model.predict(inference_batch, verbose=0)\n",
        "\n",
        "# Time the inference\n",
        "print(\"\\nTiming FP32 model inference...\")\n",
        "start_time = time.time()\n",
        "_ = fp32_model.predict(inference_batch, verbose=0)\n",
        "end_time = time.time()\n",
        "fp32_inference_time = (end_time - start_time) * 1000 # in milliseconds\n",
        "print(f\"FP32 Model Inference Time: {fp32_inference_time:.4f} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMDAWAUhsMBd"
      },
      "source": [
        "#### Apply quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wtaPSnSsDNc",
        "outputId": "084850f7-3227-40d4-cbd9-9f157a364a6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmpko0k80v5'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 30, 40, 1), dtype=tf.float32, name='input_layer_14')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 35), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138134946069200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134946068240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134946069968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134946065168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134946068816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134946067664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134946066320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134946065936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134946067088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134946067472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134946069008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134946066704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134611558864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134611560400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134611560784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134611559440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134611560592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134611559824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134611559056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138134611563280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Quantized INT8 model saved as 'final_model_quant.tflite'\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Create a representative dataset generator ---\n",
        "# This helps the converter figure out the data ranges for activations.\n",
        "def representative_dataset_gen():\n",
        "  # Use a small sample from your training data (e.g., ~100-200 images)\n",
        "  for images, _ in train_ds.take(100):\n",
        "    yield [images]\n",
        "\n",
        "# --- 2. Convert the model ---\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(fp32_model)\n",
        "\n",
        "# This enables full integer quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "# This ensures the model is strictly integer-only for max performance\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "# Convert and save the quantized model\n",
        "tflite_quant_model = converter.convert()\n",
        "with open('models/final_model_quant.tflite', 'wb') as f:\n",
        "  f.write(tflite_quant_model)\n",
        "\n",
        "print(\"\\n✅ Quantized INT8 model saved as 'final_model_quant.tflite'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG3JizVXsOS4"
      },
      "source": [
        "#### Benchmark the final quantized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU2Q579MsHbR",
        "outputId": "cba0e917-1161-45bd-e33e-45966ba9a49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating INT8 TFLite model accuracy...\n",
            "INT8 TFLite Model Accuracy: 99.7840%\n",
            "\n",
            "Timing INT8 TFLite model inference...\n",
            "INT8 TFLite Model Inference Time: 0.4947 ms\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Load the TFLite model and allocate tensors ---\n",
        "interpreter = tf.lite.Interpreter(model_path='models/final_model_quant.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()[0]\n",
        "output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "# --- 2. Evaluate Accuracy on the validation set ---\n",
        "print(\"\\nEvaluating INT8 TFLite model accuracy...\")\n",
        "correct_predictions = 0\n",
        "total_images = 0\n",
        "for images, labels in val_ds:\n",
        "  for i in range(images.shape[0]):\n",
        "    # Get a single image and check if it needs to be quantized\n",
        "    image = images[i:i+1]\n",
        "    if input_details['dtype'] == np.int8:\n",
        "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "      image = tf.cast((image / input_scale + input_zero_point), dtype=tf.int8)\n",
        "\n",
        "    interpreter.set_tensor(input_details['index'], image)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details['index'])\n",
        "\n",
        "    if np.argmax(output) == labels[i]:\n",
        "      correct_predictions += 1\n",
        "    total_images += 1\n",
        "\n",
        "int8_accuracy = correct_predictions / total_images\n",
        "print(f\"INT8 TFLite Model Accuracy: {int8_accuracy * 100:.4f}%\")\n",
        "\n",
        "# --- 3. Measure Inference Speed ---\n",
        "print(\"\\nTiming INT8 TFLite model inference...\")\n",
        "interpreter.set_tensor(input_details['index'], image) # Use the last image for timing\n",
        "# Warm up\n",
        "interpreter.invoke()\n",
        "# Time it\n",
        "start_time = time.time()\n",
        "interpreter.invoke()\n",
        "end_time = time.time()\n",
        "int8_inference_time = (end_time - start_time) * 1000 # in milliseconds\n",
        "print(f\"INT8 TFLite Model Inference Time: {int8_inference_time:.4f} ms\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.12.11)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
