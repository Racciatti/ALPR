# ALPR - Automatic License Plate Recognition

> A high-performance CNN for vehicle license plate character recognition optimized for edge computing

## ğŸ“‹ Overview

This project implements a complete **Automatic License Plate Recognition (ALPR)** solution specifically focused on individual character recognition using a custom Convolutional Neural Network. The main objective was to develop a model that combines **high accuracy** with **extreme computational efficiency**.

### ğŸ¯ Results Achieved

| Metric | Original Model (FP32) | Quantized Model (INT8) | Improvement |
|---------|------------------------|--------------------------|----------|
| **Accuracy** | 99.80% | 99.78% | -0.02% (negligible) |
| **Inference Time** | 70.41ms | 0.49ms | **143x faster** |
| **Model Size** | ~2.4MB | ~0.6MB | **4x smaller** |

## ğŸ—ï¸ Model Architecture

### Custom CNN (LeNet-inspired)
```
Input: (30, 40, 1) - Grayscale images
â”‚
â”œâ”€ Conv2D(32, 3x3) â†’ BatchNorm â†’ MaxPool2D(2x2)
â”œâ”€ Conv2D(64, 3x3) â†’ BatchNorm â†’ MaxPool2D(2x2)
â”‚
â”œâ”€ Flatten
â”œâ”€ Dense(128) â†’ BatchNorm â†’ Dropout(0.4)
â””â”€ Dense(35) â†’ Softmax
```

### Recognized Classes (35 total)
- **Digits**: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
- **Letters**: A, B, C, D, E, F, G, H, I, J, K, L, M, N, P, Q, R, S, T, U, V, W, X, Y, Z

## ğŸ”„ Processing Pipeline

### 1. Preprocessing
```
Original Data â†’ Resizing (40x30) â†’ Binarization (Otsu) â†’ Cleaning â†’ Data Augmentation
```

- **Resizing**: 100x75 --> 40x30 (6.25x reduction in pixel count)
- **Binarization**: Otsu method for optimal segmentation
- **Automatic cleaning**: Removal of low-quality samples (~10% of dataset)
- **Data augmentation**: 10x increase in sample count

### 2. Data Structure
```
data/
â”œâ”€â”€ train/           # Original training data
â”œâ”€â”€ eval/            # Original test data
â”œâ”€â”€ resized/         # Resized images
â”œâ”€â”€ thresholded/     # Binarized images
â”œâ”€â”€ cleaned/         # Clean data
â”œâ”€â”€ augmented_data/  # Augmented data (final training)
â””â”€â”€ processed_eval/  # Processed evaluation data
```

## âš™ï¸ Optimization and Training

### Systematic Methodology
1. **Hyperparameter search**: Learning rate, model capacity, dropout
2. **Refined training**: Advanced callbacks with adaptive LR reduction
3. **Final polishing**: Fine-tuning with ultra-low learning rate
4. **Quantization**: Conversion to INT8 using TensorFlow Lite

## ğŸš€ Installation and Usage

### Prerequisites
```bash
Python 3.8+
CUDA (optional, for GPU training)
```

### Installation
```bash
git clone https://github.com/racciatti/alpr.git
cd alpr
python -m venv venv
activate virtual environment (OS dependent)
pip install -r requirements.txt
```

### Basic Usage
```python
import tensorflow as tf

# Load quantized model
interpreter = tf.lite.Interpreter(model_path='models/final_model_quant.tflite')
interpreter.allocate_tensors()

# Make prediction on preprocessed image
# ... preprocessing code ...
interpreter.set_tensor(input_details['index'], processed_image)
interpreter.invoke()
prediction = interpreter.get_tensor(output_details['index'])
```

## ğŸ“Š Project Structure

```
alpr/
â”œâ”€â”€ data.ipynb              # Data processing pipeline
â”œâ”€â”€ model.ipynb             # Model training and optimization
â”œâ”€â”€ challenge_report.md     # Competition report
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ README.md              # This file
```

## ğŸ”¬ Key Technologies

- **TensorFlow/Keras**: Deep learning framework
- **OpenCV**: Image processing
- **Albumentations**: Data augmentation
- **TensorFlow Lite**: Optimization and quantization
- **scikit-learn**: Metrics and evaluation

## ğŸ“ˆ Performance

The model was specifically optimized for:
- **Real-time applications**
- **Resource-constrained devices**
- **Edge computing**
- **Low power consumption**

### Testing Environment
- **Hardware**: Google Colab GPU T4
- **Dataset**: 251,471 training images, 10,650 validation images

## ğŸ“„ License

This project is licensed under [LICENSE](LICENSE).

## ğŸ¤ Contributions

Contributions are welcome! Please open an issue or pull request to discuss significant changes.

---

**Developed over ~6 hours for a FCT UNESP competition.**

---

# ALPR - Automatic License Plate Recognition

> Uma CNN de alto desempenho para reconhecimento de caracteres de placas veiculares otimizada para edge computing

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa uma soluÃ§Ã£o completa de **Reconhecimento AutomÃ¡tico de Placas (ALPR)** focada especificamente no reconhecimento de caracteres individuais usando uma Rede Neural Convolucional customizada. O objetivo principal foi desenvolver um modelo que combine **alta precisÃ£o** com **extrema eficiÃªncia computacional**.

### ğŸ¯ Resultados AlcanÃ§ados

| MÃ©trica | Modelo Original (FP32) | Modelo Quantizado (INT8) | Melhoria |
|---------|------------------------|--------------------------|----------|
| **PrecisÃ£o** | 99,80% | 99,78% | -0,02% (negligÃ­vel) |
| **Tempo de InferÃªncia** | 70,41ms | 0,49ms | **143x mais rÃ¡pido** |
| **Tamanho do Modelo** | ~2,4MB | ~0,6MB | **4x menor** |

## ğŸ—ï¸ Arquitetura do Modelo

### CNN Customizada (Inspirada na LeNet)
```
Entrada: (30, 40, 1) - Imagens em escala de cinza
â”‚
â”œâ”€ Conv2D(32, 3x3) â†’ BatchNorm â†’ MaxPool2D(2x2)
â”œâ”€ Conv2D(64, 3x3) â†’ BatchNorm â†’ MaxPool2D(2x2)
â”‚
â”œâ”€ Flatten
â”œâ”€ Dense(128) â†’ BatchNorm â†’ Dropout(0.4)
â””â”€ Dense(35) â†’ Softmax
```

### Classes Reconhecidas (35 total)
- **DÃ­gitos**: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
- **Letras**: A, B, C, D, E, F, G, H, I, J, K, L, M, N, P, Q, R, S, T, U, V, W, X, Y, Z

## ğŸ”„ Pipeline de Processamento

### 1. PrÃ©-processamento
```
Dados Originais â†’ Redimensionamento (40x30) â†’ BinarizaÃ§Ã£o (Otsu) â†’ Limpeza â†’ Aumento de Dados
```

- **Redimensionamento**: 100x75 --> 40x30 (reduÃ§Ã£o de 6.25x no nÃºmero de pixels)
- **BinarizaÃ§Ã£o**: MÃ©todo de Otsu para segmentaÃ§Ã£o Ã³tima
- **Limpeza automÃ¡tica**: RemoÃ§Ã£o das amostras de baixa qualidade (~10% do dataset)
- **Data augmentation**: Aumento de 10x do nÃºmero de amostras

### 2. Estrutura dos Dados
```
data/
â”œâ”€â”€ train/           # Dados originais de treinamento
â”œâ”€â”€ eval/            # Dados originais de teste
â”œâ”€â”€ resized/         # Imagens redimensionadas
â”œâ”€â”€ thresholded/     # Imagens limizarizadas
â”œâ”€â”€ cleaned/         # Dados limpos
â”œâ”€â”€ augmented_data/  # Dados aumentados (treinamento final)
â””â”€â”€ processed_eval/  # Dados de avaliaÃ§Ã£o processados
```

## âš™ï¸ OtimizaÃ§Ã£o e Treinamento

### Metodologia SistemÃ¡tica
1. **Busca de hiperparÃ¢metros**: Taxa de aprendizado, capacidade do modelo, dropout
2. **Treinamento refinado**: Callbacks avanÃ§ados com reduÃ§Ã£o adaptativa de LR
3. **Polimento final**: Fine-tuning com taxa de aprendizado ultra-baixa
4. **QuantizaÃ§Ã£o**: ConversÃ£o para INT8 usando TensorFlow Lite

## ğŸš€ InstalaÃ§Ã£o e Uso

### PrÃ©-requisitos
```bash
Python 3.8+
CUDA (opcional, para treinamento com GPU)
```

### InstalaÃ§Ã£o
```bash
git clone https://github.com/racciatti/alpr.git
cd alpr
python -m venv venv
ativar ambiente virtual (depende do OS)
pip install -r requirements.txt
```

### Uso BÃ¡sico
```python
import tensorflow as tf

# Carregar modelo quantizado
interpreter = tf.lite.Interpreter(model_path='models/final_model_quant.tflite')
interpreter.allocate_tensors()

# Fazer prediÃ§Ã£o em imagem preprocessada
# ... cÃ³digo de preprocessing ...
interpreter.set_tensor(input_details['index'], processed_image)
interpreter.invoke()
prediction = interpreter.get_tensor(output_details['index'])
```

## ğŸ“Š Estrutura do Projeto

```
alpr/
â”œâ”€â”€ data.ipynb              # Pipeline de processamento de dados
â”œâ”€â”€ model.ipynb             # Treinamento e otimizaÃ§Ã£o do modelo
â”œâ”€â”€ challenge_report.md     # RelatÃ³rio para competiÃ§Ã£o
â”œâ”€â”€ requirements.txt        # DependÃªncias
â””â”€â”€ README.md              # Este arquivo
```

## ğŸ”¬ Principais Tecnologias

- **TensorFlow/Keras**: Framework de deep learning
- **OpenCV**: Processamento de imagens
- **Albumentations**: Data augmentation
- **TensorFlow Lite**: OtimizaÃ§Ã£o e quantizaÃ§Ã£o
- **scikit-learn**: MÃ©tricas e avaliaÃ§Ã£o

## ğŸ“ˆ Performance

O modelo foi otimizado especificamente para:
- **AplicaÃ§Ãµes em tempo real**
- **Dispositivos com recursos limitados**
- **Edge computing**
- **Baixo consumo energÃ©tico**

### Ambiente de Teste
- **Hardware**: Google Colab GPU T4
- **Dataset**: 251.471 imagens de treinamento, 10.650 de validaÃ§Ã£o

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob [LICENSE](LICENSE).

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, abra uma issue ou pull request para discutir mudanÃ§as significativas.

---

**Desenvolvido ao longo de ~6 horas para uma competiÃ§Ã£o da FCT UNESP.**
